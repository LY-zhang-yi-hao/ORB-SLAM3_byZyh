# ORB-SLAM3 中自定义坐标系与位姿获取的深度解析与优化 🚀

## 1. 🎯 引言：目标与背景

本文档旨在深入分析在 ORB-SLAM3 系统中，如何实现一个稳定、高效、可扩展的模块，用于实时获取相机在**自定义世界坐标系**下的位姿。

#### 核心问题
1.  **获取时机**: 在 `Tracking` 线程复杂的跟踪流程中，何时是获取位姿的"最佳"时机？
2.  **坐标变换**: 如何正确地将 SLAM 内部位姿转换到我们指定的自定义坐标系下？

#### 设计方案
- 我们将采用经典的 **观察者（Observer）设计模式**。
- `Tracking` 线程作为**被观察者（Subject）**，在计算出每帧的有效位姿后，负责进行坐标变换，并通知所有已注册的**观察者（Observer）**。

---

## 2. 🧠 核心跟踪流程：`Tracking` 线程如何计算位姿？

要获取位姿，首先必须理解位姿是如何产生的。这部分将以单目为例，详细剖析 `GrabImageMonocular` 方法返回的位姿的完整生命周期。

### 2.1. 入口点: `System::TrackMonocular`

外部通过调用 `System` 类的 `TrackMonocular` 等方法，将图像和传感器数据送入 SLAM 系统。

![image.png](https://bu.dusays.com/2025/06/05/68419d9a23f14.png)

### 2.2. 数据封装: `Tracking::GrabImageMonocular`

`System` 类的方法会进一步调用 `Tracking` 线程对应的 `GrabImageMonocular` 方法。

![image.png](https://bu.dusays.com/2025/06/05/68419ef702d7a.png)

此方法主要完成三件事：
1.  **数据封装**: 将图像、时间戳等信息封装成一个 `Frame` 对象，即 `mCurrentFrame`。
2.  **调用核心**: 调用 `Tracking::Track()` 方法，这是所有跟踪逻辑的核心。`Track()` 执行完毕后，`mCurrentFrame` 的位姿 `mTcw` 将被更新。
3.  **返回位姿**: 方法最后返回 `mCurrentFrame.GetPoseInverse()`，即 `mCurrentFrame.mTwc`。这是**相机在ORB-SLAM世界坐标系下的位姿** (T_world_camera)。

> [!NOTE]
> **坐标系术语澄清**:
> * `mTcw`: 将**世界坐标系**下的点变换到**相机坐标系**的变换矩阵。
> * `mTwc`: `mTcw` 的逆，表示**相机在世界坐标系中的位姿**，即将相机坐标系下的点变换到世界坐标系。
> * `Frame::GetPose()` 返回 `mTcw`。
> * `Frame::GetPoseInverse()` 返回 `mTwc`。

### 2.3. 跟踪核心: `Tracking::Track()` 详解

`Track()` 方法是整个跟踪过程的心脏。它是一个状态机，根据系统当前状态，按顺序尝试不同的策略来为 `mCurrentFrame` 定位。

![image.png](https://bu.dusays.com/2025/06/05/68419fb998cf0.png)

- **状态 1：系统未初始化 (NOT_INITIALIZED)**
  - 尝试进行单目初始化 (`MonocularInitialization`)，计算初始位姿和地图。

- **状态 2：系统已初始化 (OK)**
  1.  **IMU 预积分 (若有)**: 利用 IMU 数据预测当前帧的初始位姿。
  2.  **运动模型跟踪 (`TrackWithMotionModel`)**: 基于上一帧的速度预测当前位姿，并与上一帧的地图点进行快速匹配。这是最理想、最高效的情况。
  3.  **参考关键帧跟踪 (`TrackReferenceKeyFrame`)**: 如果运动模型跟踪失败，则尝试与最近的关键帧进行匹配定位。
  4.  **局部地图跟踪 (`TrackLocalMap`)**: **这是最关键的位姿优化步骤**。
     -  系统会构建一个由附近关键帧及其观测到的地图点组成的"局部地图"。
     -  将当前帧的特征点与局部地图中的所有点进行匹配，并通过 BA 优化（`Optimizer::PoseOptimization`）来最小化重投影误差。
     -  这一步极大地提高了位姿的准确性和鲁棒性，因为它利用了 `LocalMapping` 线程优化过的局部地图信息，而非孤立地处理当前帧。
  5.  **重定位 (`Relocalization`)**: 如果以上所有方法都失败（即跟踪丢失 `mState == LOST`），系统会启动重定位模块，尝试在整个地图中重新找到自己的位置。

#### 结论
> [!success]
> `GrabImage...` 方法返回的位姿 `mCurrentFrame.mTwc`，是在 `Track()` 方法中经过上述一系列步骤（特别是 `TrackLocalMap` 优化）后得到的 **`Tracking` 线程对当前帧位姿的最佳估计**。对于需要实时响应的应用（如机器人导航），这个位姿是最新且最可靠的。

---

## 3. 🌍 "最终位姿"的相对性：多线程视角

ORB-SLAM3 是一个典型的多线程系统（`Tracking`, `LocalMapping`, `LoopClosing`）。理解线程间的关系，对于理解位姿的"最终性"至关重要。

- **`Tracking` 线程**: 追求**实时性**。它产出的位姿是实时的，但不是全局最优的。
- **`LocalMapping` 线程**: 负责将新的关键帧加入地图，并进行局部 BA 优化，使局部区域的地图和关键帧位姿更精确。
- **`LoopClosing` 线程**: 当检测到回环时，会进行位姿图优化和全局 BA。这会**全局性地修正**过去所有关键帧的位姿。这种修正是**回顾性**的，会带来地图和轨迹的整体精度提升，但也会导致位姿的"跳变"。

> [!tip]
> - 对于**实时应用**（如导航、AR），`Tracking` 线程输出的位姿是唯一可用且最佳的选择。
> - 对于**离线应用**（如三维重建），应在 SLAM 运行结束后，从 `KeyFrameDatabase` 中获取经过全局优化后的最终轨迹。

---

## 4. 🛠️ 实现方案：基于观察者模式的位姿发布系统

现在，我们来设计如何在 `Tracking` 线程中，优雅地实现自定义坐标系下的位姿发布。

### 4.1. `IPoseObserver` 接口定义
定义一个纯虚基类作为接口，任何想接收位姿更新的类都应继承它。

- **`Tracking.h`**
```cpp
class IPoseObserver 
{
public:
    /**
     * @brief 虚析构函数 (Virtual destructor)
     * 确保通过基类指针删除派生类对象时能够正确调用派生类的析构函数。
     */
    virtual ~IPoseObserver() = default;
    
    /**
     * @brief 当新的位姿可用时被调用 (Called when a new pose is available)
     * @param T_custom_world_camera 相机在用户自定义世界坐标系下的位姿 (SE3 transform: pose of the camera in the custom world coordinate system)
     * 通常是 Sophus::SE3f 类型。
     * @param timestamp 帧的时间戳
     */
    virtual void OnPoseUpdated(const Sophus::SE3f& T_custom_world_camera, double timestamp) = 0;
};
```

### 4.2. 观察者管理
在 `Tracking` 类中实现观察者的注册、注销和存储。

- **`Tracking.h` (Public methods)**
```cpp
    // 注册位姿观察者对象，用于接收相机位姿更新信息
    // 支持注册多个观察者
    void RegisterPoseObserver(IPoseObserver* pObserver);

    // 取消注册位姿观察者
    void UnregisterPoseObserver(IPoseObserver* pObserver);
```
- **`Tracking.h` (Private members)**
```cpp
    std::vector<IPoseObserver*> mvpPoseObservers;
    std::mutex mMutexPoseAccess; // 用于保护观察者列表的互斥锁
```

### 4.3. 设置自定义坐标系变换
提供一个方法来设置自定义坐标系与 ORB-SLAM 内部世界坐标系的变换关系。

- **`Tracking.h`**
```cpp
/**
 * @brief Sets the transformation from the ORB-SLAM world to the custom world coordinate system.
 * @param T_custom_orb The transform T_custom_orb, which transforms a point from ORB-SLAM world to custom world: p_custom = T_custom_orb * p_orb.
 */
void SetCustomWorldTransform(const Sophus::SE3f& T_custom_orb);

// Private members
Sophus::SE3f mT_custom_orb; // Stores T_custom_orb
std::mutex mMutexTransform; // 如果变换关系可能在运行时改变，则需要互斥锁保护
```

### 4.4. 通知与坐标变换

这是将所有部分连接起来的关键。在 `Tracking::Track()` 方法的末尾，当计算出有效位姿且 `mState == OK` 之后，执行通知逻辑。

- **`Tracking.cc` in `Track()` method**
```cpp
   // ... tracking logic ...

   // 跟踪成功后，mState 会被设置为 OK
   // 如果有注册的位姿观察者，则进行通知
   if(!mvpPoseObservers.empty() && mState == OK)
   {
       // 1. 获取相机在ORB-SLAM世界坐标系下的位姿 (T_orb_c)
       //    mCurrentFrame.GetPoseInverse() 返回的是 mTwc, 即 T_orb_c
       const Sophus::SE3f T_orb_c = mCurrentFrame.GetPoseInverse();
       
       // 2. 计算相机在自定义世界坐标系下的位姿 (T_custom_c)
       //    公式: T_custom_c = T_custom_orb * T_orb_c
       Sophus::SE3f T_custom_c;
       {
           std::unique_lock<std::mutex> lock(mMutexTransform); // 保护 mT_custom_orb
           T_custom_c = mT_custom_orb * T_orb_c;
       }
       
       // 3. 遍历并通知所有观察者
       std::unique_lock<std::mutex> lock(mMutexPoseAccess); // 保护 mvpPoseObservers
       for(auto pObserver : mvpPoseObservers) {
           if(pObserver) {
               pObserver->OnPoseUpdated(T_custom_c, mCurrentFrame.mTimeStamp);
           }
       }
   }
```
> [!warning]
> **关于您代码的说明**
> 您在之前编辑中提供的代码段，虽然变量命名（如 `Twc` `Tcw`）可能与标准约定略有出入，但其核心数学逻辑 `mT_custom_orb * mCurrentFrame.GetPose().inverse()` 是完全正确的。上面的代码片段采用了更符合惯例的命名 (`T_orb_c`) 以增强可读性，但最终计算结果与您的代码是一致的。

---

## 5. ✅ 整合流程与优化建议

### 5.1. 完整数据流
1.  **外部调用**: `System::TrackMonocular(image, timestamp, ...)`
2.  **进入跟踪**: `Tracking::GrabImageMonocular` 封装 `Frame` 并调用 `Tracking::Track()`。
3.  **位姿计算**: `Track()` 内部通过 `TrackLocalMap` 等步骤，计算出 `mCurrentFrame.mTcw`。
4.  **状态检查**: 确认跟踪成功 `mState == OK`。
5.  **坐标变换**: 在 `Track()` 末尾计算 `T_custom_c = mT_custom_orb * mCurrentFrame.mTcw.inverse()`。
6.  **发布通知**: 遍历观察者列表，调用 `OnPoseUpdated` 并传递 `T_custom_c` 和时间戳。
7.  **返回位姿**: `GrabImageMonocular` 向最初的调用者返回 `mCurrentFrame.mTcw.inverse()`。

### 5.2. 优化与注意事项
- 🔐 **线程安全**: `mvpPoseObservers` 和 `mT_custom_orb` 的所有访问（增、删、改、查）都必须由互斥锁保护，以防止多线程冲突。
- ⚡️ **回调性能**: `OnPoseUpdated` 的实现应该是**轻量级**的。避免在回调函数中执行任何耗时操作（如文件 I/O、复杂计算），否则会直接阻塞 `Tracking` 线程，严重影响 SLAM 的实时性和稳定性。推荐的做法是，在回调中仅将位姿数据拷贝到线程安全的队列中，由另一个工作线程进行消费。
- 🤷‍♂️ **跟踪丢失处理**: 当 `mState` 不是 `OK` 时（例如为 `LOST`），`Tracking` 线程不会更新位姿。此时不应通知观察者，或者可以根据应用需求，发送一个"无效位姿"的特殊信号。
-  clarity **坐标系定义清晰**: `SetCustomWorldTransform` 的参数 `T_custom_orb` 的变换方向 (`ORB -> Custom` 还是 `Custom -> ORB`) 必须有清晰的文档和代码注释，以避免使用者混淆。根据我们的推导，它应该是 `T_custom_orb`。

---

## 6. 💡 实例：在 `mono_euroc.cc` 中使用

理论和设计最终需要落实在代码中。`Examples/Monocular/mono_euroc.cc` 提供了一个绝佳的范例，展示了如何使用我们设计的观察者模式来记录自定义坐标系下的相机轨迹。

### 6.1. 创建具体的观察者 `TUMFormatTrajectoryRecorder`
这是观察者模式的实践核心：创建一个继承自 `IPoseObserver` 的具体类。

- **`Examples/Monocular/mono_euroc.cc`**
```cpp
// 按照ORB-SLAM3的TUM格式，轨迹记录
class TUMFormatTrajectoryRecorder : public ORB_SLAM3::IPoseObserver
{
private:
    std::ofstream mOutputFile; // 文件流，用于写入轨迹数据
    // ... 其他成员 ...

public:
    TUMFormatTrajectoryRecorder(const std::string& filename, ...);
    ~TUMFormatTrajectoryRecorder();
    
    // 核心：实现基类的纯虚函数
    void OnPoseUpdated(const Sophus::SE3f& T_custom_world_camera, double timestamp) override 
    {
        if (!mOutputFile.is_open()) return;        
        
        // 获取平移向量
        Eigen::Vector3f twc = T_custom_world_camera.translation();
        // 获取单位四元数
        Eigen::Quaternionf q = T_custom_world_camera.unit_quaternion();
        
        // 以TUM格式将 时间戳、平移、旋转（四元数）写入文件
        mOutputFile << std::setprecision(6) << timestamp << " "
                    << std::setprecision(9) 
                    << twc.x() << " " << twc.y() << " " << twc.z() << " "
                    << q.w() << " " << q.x() << " " << q.y() << " " << q.z() 
                    << std::endl;        
    }
};
```
这个类 `TUMFormatTrajectoryRecorder` 的唯一职责就是将接收到的位姿 `T_custom_world_camera` 格式化并写入文件。这完全符合我们对回调函数"轻量级"的要求。

### 6.2. 在 `main` 函数中设置和注册观察者
在主程序入口，我们需要完成所有设置工作。

- **`Examples/Monocular/mono_euroc.cc`**
```cpp
int main(int argc, char **argv)
{  
    // ... 初始化SLAM系统 ...
    ORB_SLAM3::System SLAM(argv[1], argv[2], ORB_SLAM3::System::MONOCULAR, true);

    // 1. 获取对 Tracking 对象的引用
    ORB_SLAM3::Tracking* pTracker = SLAM.GetTracker();
    if (pTracker) {

        // 2. 定义自定义坐标系到ORB坐标系的变换 T_custom_orb
        //    假设ORB坐标系原点在自定义世界坐标的(1.5, 2.2, 0)，且姿态一致
        Eigen::Vector3f t_custom_orb_translation(1.5, 2.2, 0);
        Eigen::Matrix3f R_custom_orb = Eigen::Matrix3f::Identity();
        Sophus::SE3f T_custom_orb(R_custom_orb, t_custom_orb_translation);
        
        // 3. 设置变换
        pTracker->SetCustomWorldTransform(T_custom_orb);

        // 4. 创建观察者实例
        std::string customTrajFile = "f_custom_"+ std::string(argv[5]) + ".txt";
        TUMFormatTrajectoryRecorder* pTrajectoryRecorder = new TUMFormatTrajectoryRecorder(customTrajFile, false);
        
        // 5. 注册观察者
        pTracker->RegisterPoseObserver(pTrajectoryRecorder);
        
        std::cout << "🔄 已注册自定义坐标系轨迹记录器..." << std::endl;
    } 
    
    // ... 主循环，调用 SLAM.TrackMonocular(...) ...
    for(int ni=0; ni<nImages[seq]; ni++)
    {
        // ...
        SLAM.TrackMonocular(im, tframe); 
        // ...
    }

    // ... 结束 ...
    SLAM.Shutdown();
    
    return 0;
}
```
这段代码清晰地展示了整个流程：
1.  **获取Tracker**: 从 `System` 对象中获取 `Tracking` 对象的指针。
2.  **定义变换**: 创建一个 `Sophus::SE3f` 实例来表示 `T_custom_orb`。
3.  **设置变换**: 调用 `SetCustomWorldTransform` 将其传递给 `Tracking` 模块。
4.  **实例化观察者**: 创建 `TUMFormatTrajectoryRecorder` 对象，它会自动打开一个文件用于写入。
5.  **注册观察者**: 调用 `RegisterPoseObserver` 将其"挂载"到 `Tracking` 线程的通知列表上。

此后，每次 `Tracking` 线程成功跟踪一帧图像，`pTrajectoryRecorder->OnPoseUpdated(...)` 就会被自动调用，从而将自定义坐标系下的位姿实时记录到文件中。